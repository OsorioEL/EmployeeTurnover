{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Statement:\n",
    "### Portobello Tech is an app innovator who has devised an intelligent way of predicting employee turnover within the company. It periodically evaluates employees' work details, including the number of projects they worked on, average monthly working hours, time spent in the company, promotions in the last five years, and salary level.\n",
    "### Data from prior evaluations shows the employeesâ€™ satisfaction in the workplace. The data could be used to identify patterns in work style and their interest in continuing to work for the company.\n",
    "### The HR Department owns the data and uses it to predict employee turnover. Employee turnover refers to the total number of workers who leave a company over time.\n",
    "### As the ML Developer assigned to the HR Department, we have been asked to create ML programs to:\n",
    "### 1. Perform data quality checks by checking for missing values, if any.\n",
    "### 2. Understand what factors contributed most to employee turnover at EDA.\n",
    "### 3. Perform clustering of employees who left based on their satisfaction and evaluation.\n",
    "### 4. Handle the left Class Imbalance using the SMOTE technique.\n",
    "### 5. Perform k-fold cross-validation model training and evaluate performance.\n",
    "### 6. Identify the best model and justify the evaluation metrics used.\n",
    "### 7. Suggest various retention strategies for targeted employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into a data frame and check firtst 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open hr_comma_sep.csv\n",
    "df = pd.read_csv('hr_comma_sep.csv')\n",
    "\n",
    "# check head of the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It appears that there are 10 columns in the dataset and the 9th column is wrongly labeld as 'sales' whereas it appears to hold the value of the 'department' to which the employee belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique value of the 'sales' column\n",
    "print(df['sales'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will change the 'sales' column name to 'department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the name of the column 'sales' to 'department'\n",
    "df.rename(columns = {'sales':'department'}, inplace = True)\n",
    "\n",
    "# print column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print information about the data frame to identify any missing values or other anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check info of the data\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It does not appear that any of the columns in our data set have missing values\n",
    "### We will now check for unique values for our 10 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values for each of the 10 columns in the data\n",
    "for col in df.columns:\n",
    "    print(col, df[col].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now describe the data in the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desicribe numerical columns\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Visualizations for the columns that might play a factor in people leaving. Starting with Satisfaction Levels which seems a logical feature that would affect people's decision to stay in the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the distribution of the numerical columns\n",
    "# plot satisfaction_level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['satisfaction_level'], kde=True)\n",
    "plt.title('Distribution of Satisfaction Level for all employees')\n",
    "plt.show()\n",
    "\n",
    "# Print mean satisfaction level for dataset\n",
    "print('Mean Satisfaction Level for dataset:',df['satisfaction_level'].mean())\n",
    "\n",
    "# Plot satisfaction level for those who left \n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df[df['left']==1]['satisfaction_level'], kde=True, color='red', label='Left',bins=50)\n",
    "#sns.histplot(df[df['left']==0]['satisfaction_level'], kde=True, color='green', label='Stayed')\n",
    "plt.title('Distribution of Satisfaction Level for those who left')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# print mean satisfaction level for those who left\n",
    "print('Mean Satisfaction Level for those who left:',df[df['left']==1]['satisfaction_level'].mean())\n",
    "\n",
    "# plot satisfaction_level for those who stayed\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df[df['left']==0]['satisfaction_level'], kde=True, color='green', label='Stayed',bins=50)\n",
    "plt.title('Distribution of Satisfaction Level for those who stayed')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Total number of employees who left the company\n",
    "print('Total number of employees who left the company:',df[df['left']==1].shape[0])\n",
    "print()\n",
    "# print mean satisfaction level for those who stayed\n",
    "print('Mean Satisfaction Level for those who stayed:',df[df['left']==0]['satisfaction_level'].mean())\n",
    "print()\n",
    "#Total number of employees with satisfaction level less than .1\n",
    "print('Total number of employees with satisfaction level less than .1:',df[df['satisfaction_level']<0.1].shape[0])\n",
    "# Total number of employees with satisfaction level less than .1 who left\n",
    "print('Total number of employees with satisfaction level less than .1 who left:',df[(df['satisfaction_level']<0.1) & (df['left']==1)].shape[0])\n",
    "\n",
    "# Total percentage of employees with satisfaction level less than .1 who left\n",
    "print('Percentage of employees with satisfaction level less than .1 who left:',round(df[(df['satisfaction_level']<0.1) & (df['left']==1)].shape[0]/df[df['satisfaction_level']<0.1].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level less than .1 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level less than .1 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']<0.1) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "print()\n",
    "\n",
    "# Total number of employees with satisfaction level less than .15\n",
    "print('Total number of employees with satisfaction level less than .15:',df[df['satisfaction_level']<0.15].shape[0])\n",
    "# Total number of employees with satisfaction level less than .15 who left\n",
    "print('Total number of employees with satisfaction level less than .15 who left:',df[(df['satisfaction_level']<0.15) & (df['left']==1)].shape[0])\n",
    "#Total percentage of employees with satisfaction level less than .15 who left\n",
    "print('Percentage of employees with satisfaction level less than .15 who left:',round(df[(df['satisfaction_level']<0.15) & (df['left']==1)].shape[0]/df[df['satisfaction_level']<0.15].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level less than .15 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level less than .15 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']<0.15) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "print()\n",
    "\n",
    "#Total number of employees with satisfaction level between .15 and .2\n",
    "print('Total number of employees with satisfaction level between .15 and .2:',df[(df['satisfaction_level']>=0.15) & (df['satisfaction_level']<=0.2)].shape[0])\n",
    "# Total number of employees with satisfaction level between .15 and .2 who left\n",
    "print('Total number of employees with satisfaction level between .15 and .2 who left:',df[(df['satisfaction_level']>=0.15) & (df['satisfaction_level']<=0.2) & (df['left']==1)].shape[0])\n",
    "# Total percentage of employees with satisfaction level between .15 and .2 who left\n",
    "print('Percentage of employees with satisfaction level between .15 and .2 who left:',round(df[(df['satisfaction_level']>=0.15) & (df['satisfaction_level']<=0.2) & (df['left']==1)].shape[0]/df[(df['satisfaction_level']>=0.15) & (df['satisfaction_level']<=0.2)].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level between .15 and .2 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level between .15 and .2 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']>=0.15) & (df['satisfaction_level']<=0.2) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "print()\n",
    "\n",
    "# Total Number of employees with satisfactin level less than .2\n",
    "print('Total number of employees with satisfaction level less than .2:',df[df['satisfaction_level']<0.2].shape[0])\n",
    "# Total Number of employees with satisfaction level less than .2 who left\n",
    "print('Total number of employees with satisfaction level less than .2 who left:',df[(df['satisfaction_level']<0.2) & (df['left']==1)].shape[0])\n",
    "# Total percentage of employees with satisfaction level less than .2 who left\n",
    "print('Percentage of employees with satisfaction level less than .2 who left:',round(df[(df['satisfaction_level']<0.2) & (df['left']==1)].shape[0]/df[df['satisfaction_level']<0.2].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level less than .2 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level less than .2 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']<0.2) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "print()\n",
    "\n",
    "# Total Number of employees with satisfaction level less than .375\n",
    "print('Total number of employees with satisfaction level less than .375:',df[df['satisfaction_level']<0.375].shape[0])\n",
    "# Total Number of employees with satisfaction level less than .375 who left\n",
    "print('Total number of employees with satisfaction level less than .375 who left:',df[(df['satisfaction_level']<0.375) & (df['left']==1)].shape[0])\n",
    "# Total percentage of employees with satisfaction level less than .375 who left\n",
    "print('Percentage of employees with satisfaction level less than .375 who left:',round(df[(df['satisfaction_level']<0.375) & (df['left']==1)].shape[0]/df[df['satisfaction_level']<0.375].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level less than .375 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level less than .375 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']<0.375) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "\n",
    "print()\n",
    "\n",
    "# Total Number of employees with satisfaction level beween .2 and .375\n",
    "print('Total number of employees with satisfaction level between .2 and .375:',df[(df['satisfaction_level']>=0.2) & (df['satisfaction_level']<=0.375)].shape[0])\n",
    "# Total Number of employees with satisfaction level between .2 and .375 who left\n",
    "print('Total number of employees with satisfaction level between .2 and .375 who left:',df[(df['satisfaction_level']>=0.2) & (df['satisfaction_level']<=0.375) & (df['left']==1)].shape[0])\n",
    "# Total percentage of employees with satisfaction level between .2 and .375 who left\n",
    "print('Percentage of employees with satisfaction level between .2 and .375 who left:',round(df[(df['satisfaction_level']>=0.2) & (df['satisfaction_level']<=0.375) & (df['left']==1)].shape[0]/df[(df['satisfaction_level']>=0.2) & (df['satisfaction_level']<=0.375)].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level between .2 and .375 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level between .2 and .375 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']>=0.2) & (df['satisfaction_level']<=0.375) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# Total  Number of employees with satisfaction level between .375 and .475\n",
    "print('Total number of employees with satisfaction level between .375 and .475:',df[(df['satisfaction_level']>=0.375) & (df['satisfaction_level']<=0.475)].shape[0])\n",
    "# Total Number of employees with satisfaction level between .375 and .475 who left\n",
    "print('Total number of employees with satisfaction level between .375 and .475 who left:',df[(df['satisfaction_level']>=0.375) & (df['satisfaction_level']<=0.475) & (df['left']==1)].shape[0])\n",
    "# Total percentage of employees with satisfaction level between .375 and .475 who left\n",
    "print('Percentage of employees with satisfaction level between .375 and .475 who left:',round(df[(df['satisfaction_level']>=0.375) & (df['satisfaction_level']<=0.475) & (df['left']==1)].shape[0]/df[(df['satisfaction_level']>=0.375) & (df['satisfaction_level']<=0.475)].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level between .375 and .475 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level between .375 and .475 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']>=0.375) & (df['satisfaction_level']<=0.475) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# Total Number of employees with satisfaction level less than .5\n",
    "print('Total number of employees with satisfaction level less than .5:',df[df['satisfaction_level']<0.5].shape[0])\n",
    "# Total Number of employees with satisfaction leel less than .5 who left\n",
    "print('Total number of employees with satisfaction level less than .5 who left:',df[(df['satisfaction_level']<0.5) & (df['left']==1)].shape[0])\n",
    "# Total percentage of employees with satisfaction level less than .5 who left\n",
    "print('Percentage of employees with satisfaction level less than .5 who left:',round(df[(df['satisfaction_level']<0.5) & (df['left']==1)].shape[0]/df[df['satisfaction_level']<0.5].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level less than .5 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level less than .5 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']<0.5) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "\n",
    "print()\n",
    "\n",
    "# Total Number of employees with satisfaction level between .475 and .5\n",
    "print('Total number of employees with satisfaction level between .475 and .5:',df[(df['satisfaction_level']>=0.475) & (df['satisfaction_level']<=0.5)].shape[0])\n",
    "# Total Number of employees with satisfaction level between .475 and .5 who left\n",
    "print('Total number of employees with satisfaction level between .475 and .5 who left:',df[(df['satisfaction_level']>=0.475) & (df['satisfaction_level']<=0.5) & (df['left']==1)].shape[0])\n",
    "# Total percentage of employees with satisfaction level between .475 and .5 who left\n",
    "print('Percentage of employees with satisfaction level between .475 and .5 who left:',round(df[(df['satisfaction_level']>=0.475) & (df['satisfaction_level']<=0.5) & (df['left']==1)].shape[0]/df[(df['satisfaction_level']>=0.475) & (df['satisfaction_level']<=0.5)].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level between .475 and .5 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level between .475 and .5 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']>=0.475) & (df['satisfaction_level']<=0.5) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "\n",
    "print()\n",
    "\n",
    "# Total number of employees with satisfaction level between .5 and .7 \n",
    "print('Total number of employees with satisfaction level between .5 and .7:',df[(df['satisfaction_level']>=0.5) & (df['satisfaction_level']<=0.7)].shape[0])\n",
    "# Total number of employees with satisfaction level between .5 and .7 who left\n",
    "print('Total number of employees with satisfaction level between .5 and .7 who left:',df[(df['satisfaction_level']>=0.5) & (df['satisfaction_level']<=0.7) & (df['left']==1)].shape[0])\n",
    "# Total percentage of employees with satisfaction level between .5 and .7 who left\n",
    "print('Percentage of employees with satisfaction level between .5 and .7 who left:',round(df[(df['satisfaction_level']>=0.5) & (df['satisfaction_level']<=0.7) & (df['left']==1)].shape[0]/df[(df['satisfaction_level']>=0.5) & (df['satisfaction_level']<=0.7)].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level between .5 and .7 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level between .5 and .7 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']>=0.5) & (df['satisfaction_level']<=0.7) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "\n",
    "print()\n",
    "\n",
    "# Total Number of employees with satisfaction level between .7 and 1\n",
    "print('Total number of employees with satisfaction level between .7 and 1:',df[(df['satisfaction_level']>=0.7) & (df['satisfaction_level']<=1)].shape[0])\n",
    "# Total Number of employees with satisfaction level between .7 and 1 who left\n",
    "print('Total number of employees with satisfaction level between .7 and 1 who left:',df[(df['satisfaction_level']>=0.7) & (df['satisfaction_level']<=1) & (df['left']==1)].shape[0])\n",
    "# Total percentage of employees with satisfaction level between .7 and 1 who left\n",
    "print('Percentage of employees with satisfaction level between .7 and 1 who left:',round(df[(df['satisfaction_level']>=0.7) & (df['satisfaction_level']<=1) & (df['left']==1)].shape[0]/df[(df['satisfaction_level']>=0.7) & (df['satisfaction_level']<=1)].shape[0]*100,2),'%')\n",
    "# Percentage of employees with satisfaction level between .7 and 1 who left compared to total number of employees who left\n",
    "print('Percentage of employees with satisfaction level between .7 and 1 who left compared to total number of employees who left:',round(df[(df['satisfaction_level']>=0.7) & (df['satisfaction_level']<=1) & (df['left']==1)].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the mean for the entire company for satisfaction level we see that overall employees average satisfaction level is about .61\n",
    "### Those who left have a satisfaction level of about .443\n",
    "### Those who stayed have a satisfaction level of about .66. This suggests that satisfaction level could be a factor for those who left\n",
    "\n",
    "### Going deeper into the distribution of satisfaction level, we see an interesting pattern\n",
    "### It seems that there are 3 intervals that contain the majority of those who left, about 87% of the total people who left\n",
    "### These intervals are:\n",
    "### Satisfaction level less than .15 (25.34% of overall employees who left)\n",
    "### Satisfacton level between .375 and .475 (35.37% of overall employees who left)\n",
    "### Satisfaction level greater than .7 (26.41% of overall employees who left)\n",
    "\n",
    "### As we can see, we have a lower satisfaction satisfaction level range among the employees who left, perhaps this is expected, since they are very unsatisfied in their jobs\n",
    "### However, there is a large number of people in a range which we could call a 'moderate satisfaction' level which seems to hold the largest group of employees leaving\n",
    "### Moreover, we can also see that even employees with what we could all 'high satisfaction' levels, above .7 (which is above the mean) are also leaving at slightly a higher rate than those in the 'low satisfaction' range.\n",
    "\n",
    "### So, clearly, satisfaction level is only part of the reason why people are leaving. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each of the satisfaction levels, we need to find out what is contributing to the employees leaving\n",
    "\n",
    "### We will first divide the data into data frames that group employees by satisfaction level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the satisfaction key satisfaction level ranges for the data\n",
    "satisfaction_low = df[df['satisfaction_level']<.15]\n",
    "satisfaction_med_low = df[(df['satisfaction_level']>=0.15) & (df['satisfaction_level']<0.35)]\n",
    "satisfaction_med = df[(df['satisfaction_level']>=0.35) & (df['satisfaction_level']<0.475)]\n",
    "satisfaction_med_high = df[(df['satisfaction_level']>=0.475) & (df['satisfaction_level']<0.7)]\n",
    "satisfaction_high = df[df['satisfaction_level']>=0.7]\n",
    "\n",
    "# Create List of the satisfaction levels dataframes\n",
    "satisfaction_levels = [satisfaction_low, satisfaction_med_low, satisfaction_med, satisfaction_med_high, satisfaction_high]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will next create a function that takes in a satisfaction level and returns the statistics for that satisfaction level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print out statistics for each satisfaction level range. The satisfaction_level dataframe is passed to the function\n",
    "def satisfaction_stats(satisfaction_level):\n",
    "    print('Total number of employees at this satisfaction level:',satisfaction_level.shape[0])\n",
    "    print('Total number of employees who left at this satisfaction level:',satisfaction_level[satisfaction_level['left']==1].shape[0])\n",
    "    print('Percentage of employees who left at satisfaction level compared to all employees at this satisfaction level:',round(satisfaction_level[satisfaction_level['left']==1].shape[0]/satisfaction_level.shape[0]*100,2),'%')\n",
    "    print('Percentage of employees who left at this satisfaction level compared to overall total number of employees who left:',round(satisfaction_level[satisfaction_level['left']==1].shape[0]/df[df['left']==1].shape[0]*100,2),'%')\n",
    "    print()\n",
    "    \n",
    "    # Calculate summary statistics for the passed satisfaction_level dataframe\n",
    "\n",
    "    print('Description for all employees with satisfaction level between: ',satisfaction_level['satisfaction_level'].min(),' and ',satisfaction_level['satisfaction_level'].max())\n",
    "    level_summary = satisfaction_level.describe()\n",
    "    print(level_summary)\n",
    "    print()\n",
    "    \n",
    "    # Calculate summary statistics for the satisfaction level dataframe for those who left\n",
    "    print('Description for only those employees who left with a satisfaction level between: ',satisfaction_level['satisfaction_level'].min(),' and ',satisfaction_level['satisfaction_level'].max(),' for those who left')\n",
    "    level_summary_left = satisfaction_level[satisfaction_level['left']==1].describe()\n",
    "    print(level_summary_left)\n",
    "    print()\n",
    "    \n",
    "    # Calculate summary statistics for the satisfaction level dataframe for those who stayed\n",
    "    print('Description for only those employees who stayed with a satisfaction level between: ',satisfaction_level['satisfaction_level'].min(),' and ',satisfaction_level['satisfaction_level'].max(),' for those who stayed')\n",
    "    level_summary_stayed = satisfaction_level[satisfaction_level['left']==0].describe()\n",
    "    print(level_summary_stayed)\n",
    "    print()\n",
    "    \n",
    "    # Satisfaction level mean for those who stayed vs those who left\n",
    "    print('Mean satisfaction level for those who stayed:',satisfaction_level[satisfaction_level['left']==0]['satisfaction_level'].mean())\n",
    "    print('Mean satisfaction level for those who left:',satisfaction_level[satisfaction_level['left']==1]['satisfaction_level'].mean())\n",
    "    print()\n",
    "    \n",
    "    # Last evaluation mean for those who stayed vs those who left\n",
    "    print('Mean last evaluation for those who stayed:',satisfaction_level[satisfaction_level['left']==0]['last_evaluation'].mean())\n",
    "    print('Mean last evaluation for those who left:',satisfaction_level[satisfaction_level['left']==1]['last_evaluation'].mean())\n",
    "    print()\n",
    "    \n",
    "    # Average number of projects for those who stayed vs those who left\n",
    "    print('Average number of projects for those who stayed:',satisfaction_level[satisfaction_level['left']==0]['number_project'].mean())\n",
    "    print('Average number of projects for those who left:',satisfaction_level[satisfaction_level['left']==1]['number_project'].mean())\n",
    "    print()\n",
    "    \n",
    "    # Average monthly hours for those who stayed vs those who left\n",
    "    print('Average monthly hours for those who stayed:',satisfaction_level[satisfaction_level['left']==0]['average_montly_hours'].mean())\n",
    "    print('Average monthly hours for those who left:',satisfaction_level[satisfaction_level['left']==1]['average_montly_hours'].mean())\n",
    "    print()\n",
    "    \n",
    "    # Average time spent at the company for those who stayed vs those who left\n",
    "    print('Average time spent at the company for those who stayed:',satisfaction_level[satisfaction_level['left']==0]['time_spend_company'].mean())\n",
    "    print('Average time spent at the company for those who left:',satisfaction_level[satisfaction_level['left']==1]['time_spend_company'].mean())\n",
    "    print()\n",
    "    \n",
    "    # For the categorical columns, department, salary, promotion_last_5years, and Work_accident, calculate the following statistics:\n",
    "    # Count of employees in each department at this satisfaction level\n",
    "    print('Count of employees in each department:')\n",
    "    deptcount=satisfaction_level['department'].value_counts()\n",
    "    print(deptcount)\n",
    "    # Count of employees in each departnment who left at this satisfaction level\n",
    "    print('Count of employees in each department who left:')\n",
    "    print(satisfaction_level[satisfaction_level['left']==1]['department'].value_counts())\n",
    "    print('Percentage of employees in each department who left:')\n",
    "    print(satisfaction_level[satisfaction_level['left']==1]['department'].value_counts()/satisfaction_level['department'].value_counts()*100)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print('Count of employees in each department who left:')\n",
    "    #print(satisfaction_level[satisfaction_level['left']==1]['department'].value_counts())\n",
    "    #print('Percentage of employees in each department who left:')\n",
    "    #print(satisfaction_level[satisfaction_level['left']==1]['department'].value_counts()/satisfaction_level['department'].value_counts()*100)\n",
    "    \n",
    "    print()\n",
    "    # Count of employees in each salary range\n",
    "    print('Count of employees in each salary range:')\n",
    "    print(satisfaction_level['salary'].value_counts())\n",
    "    print()\n",
    "    # Count of employees in each salary range who left at this satisfaction level\n",
    "    print('Count of employees in each salary range who left:')\n",
    "    print(satisfaction_level[satisfaction_level['left']==1]['salary'].value_counts())\n",
    "    print()\n",
    "    # Percentage of employees in each salary range who left at this satisfaction level\n",
    "    print('Percentage of employees in each salary range who left:')\n",
    "    print(satisfaction_level[satisfaction_level['left']==1]['salary'].value_counts()/satisfaction_level['salary'].value_counts()*100)\n",
    "    print()\n",
    "    \n",
    "\n",
    "    # Proportion of employees who left the company within each Work_accident range\n",
    "    print('Proportion of employees who left the company within each Work_accident range:')\n",
    "    print(satisfaction_level[satisfaction_level['left']==1]['Work_accident'].value_counts()/satisfaction_level['Work_accident'].value_counts()*100)\n",
    "    print()\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now pass the satisfaction levels dataframes starting with satisfaction_low and analyze what might be contributing to employees leaving for each of those levels of satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass satisfaction_low dataframe to satisfaction_stats function\n",
    "satisfaction_stats(satisfaction_low)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations of Factors that could be contributig to turnover per statistics above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of satisfaction level for those who left at low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_low[satisfaction_low['left']==1]['satisfaction_level'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Satisfaction Level for those who left at low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of last evaluation for those who left at low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_low[satisfaction_low['left']==1]['last_evaluation'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Last Evaluation for those who left at low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of average monthly hours for those who left at low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_low[satisfaction_low['left']==1]['average_montly_hours'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Average Monthly Hours for those who left at low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of number of projects for those who left at low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_low[satisfaction_low['left']==1]['number_project'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Number of Projects for those who left at low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of time spent at the company for those who left at low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_low[satisfaction_low['left']==1]['time_spend_company'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Time Spent at Company for those who left at low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploytly boxplot of salaries for those who left at low satisfaction level with title\n",
    "import plotly.express as px\n",
    "fig = px.box(satisfaction_low[satisfaction_low['left']==1], x='salary', y='satisfaction_level', points='all', title='Boxplot of Salaries for those who left at low satisfaction level')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Low Satisfaction Level Employees\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Total number of employees at this satisfaction level: 1045\n",
    "### Total number of employees who left: 905\n",
    "### Percentage of employees who left: 86.6%\n",
    "### Percentage of employees who left at this satisfaction level compared to the overall total: 25.34%\n",
    "\n",
    "## Satisfaction Level\n",
    "\n",
    "### The employees who left had a mean satisfaction level of 0.102, lower than the group's mean satisfaction level of 0.106 and significantly lower than the 0.132 mean for those who stayed. This suggests that dissatisfaction was a key factor driving these employees to leave. The distribution plot (see above) reinforces this, showing a concentration of employees who left around the 0.1 satisfaction level.\n",
    "\n",
    "## Last Evaluation\n",
    "\n",
    "### Interestingly, the mean last evaluation score for employees who left was 0.867, much higher than the company's overall mean of 0.716 and higher than the 0.707 mean for those who stayed. This could imply that these employees were performing well and possibly felt overworked or undervalued, despite their high performance ratings. The distribution plot of last evaluation clearly shows a skew towards higher evaluation scores for those who left.\n",
    "\n",
    "## Number of Projects\n",
    "\n",
    "### The number of projects assigned to employees who left was also notably high, with a mean of 6.16, compared to 4.4 for those who stayed and 3.8 for the entire company. This indicates that employees who were overloaded with projects were more likely to leave. The distribution plot for the number of projects highlights a significant cluster at 6 to 7 projects for those who left, which is above the average for the company.\n",
    "\n",
    "## Average Monthly Hours\n",
    "\n",
    "### The average monthly hours for those who left was 275, compared to 201 for the entire company and 205 for those who stayed. This stark difference points to overwork as a major factor in their decision to leave. The distribution plot of average monthly hours further illustrates the heavy workload on those who left.\n",
    "\n",
    "## Time Spent at Company\n",
    "\n",
    "### Employees who left had an average tenure of 4.08 years, slightly lower than the 4.7 years for those who stayed but above the company average of 3.5 years. This suggests that employees were leaving after gaining significant experience but before reaching long-term tenure milestones. The distribution plot of time spent at the company shows a peak at 4 years, indicating that many left after this period.\n",
    "\n",
    "## Departmental Analysis\n",
    "\n",
    "### Across all departments, over 80% of employees left, with HR having the highest attrition rate at 90.7%. This indicates that the issues driving employees to leave were widespread across the company, not confined to any specific department.\n",
    "\n",
    "## Salary\n",
    "\n",
    "### Salary did not appear to mitigate the high turnover. Both low and medium salary ranges had attrition rates above 85%, and even 48% of high-salary employees left. This suggests that even competitive pay could not compensate for the dissatisfaction and overwork experienced by these employees.\n",
    "\n",
    "## Promotions and Work Accidents\n",
    "\n",
    "### Promotions and work accidents seemed to have little influence on turnover at this satisfaction level. Even the small number of promoted employees all left, and while 88% of non-accident employees left, 66% of those who had accidents also left, showing no clear protective effect from either variable.\n",
    "\n",
    "## Conclusion\n",
    "### Employees with low satisfaction levels were heavily overworked, as evidenced by the high number of projects and average monthly hours. Despite their high performance evaluations, they likely felt undervalued and overwhelmed, leading to their decision to leave. Salary and promotions did not provide enough incentive to stay, and the issue was consistent across all departments. This analysis suggests a need for the company to address workload distribution and employee satisfaction more effectively to reduce turnover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass satisfaction_med_low dataframe to satisfaction_stats function\n",
    "satisfaction_stats(satisfaction_med_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of satisfaction level for those who left at mid_low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_low[satisfaction_med_low['left']==1]['satisfaction_level'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Satisfaction Level for those who left at mid_low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of last evaluation for those who left at mid_low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_low[satisfaction_med_low['left']==1]['last_evaluation'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Last Evaluation for those who left at mid_low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of average monthly hours for those who left at mid_low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_low[satisfaction_med_low['left']==1]['average_montly_hours'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Average Monthly Hours for those who left at mid_low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of number of projects for those who left at mid_low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_low[satisfaction_med_low['left']==1]['number_project'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Number of Projects for those who left at mid_low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of time spent at the company for those who left at mid_low satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_low[satisfaction_med_low['left']==1]['time_spend_company'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Time Spent at Company for those who left at mid_low satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploytly boxplot of salaries for those who left at mid_low satisfaction level with title\n",
    "import plotly.express as px\n",
    "fig = px.box(satisfaction_med_low[satisfaction_med_low['left']==1], x='salary', y='satisfaction_level', points='all', title='Boxplot of Salaries for those who left at mid_low satisfaction level')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Mid-Low Satisfaction Level Employees\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Total number of employees at this satisfaction level: 1089\n",
    "### Total number of employees who left: 74\n",
    "### Percentage of employees who left: 6.8%\n",
    "### Percentage of employees who left at this satisfaction level compared to the overall total: 2.07%\n",
    "\n",
    "## Satisfaction Level\n",
    "\n",
    "### The employees who left had a mean satisfaction level of 0.264, which is higher than the groupâ€™s overall mean satisfaction of 0.232 and the 0.229 mean for those who stayed. This might suggest that even within this mid-low range of satisfaction, those who were slightly more satisfied were still leaving. The distribution plot reveals that most employees who left clustered around the 0.3 satisfaction level, indicating a potential threshold where dissatisfaction starts to outweigh the reasons for staying.\n",
    "\n",
    "## Last Evaluation\n",
    "\n",
    "### The mean last evaluation score for employees who left was 0.670, which is slightly lower than the groupâ€™s mean of 0.695 and also lower than the 0.696 mean for those who stayed. This suggests that lower evaluations might have contributed to employees deciding to leave, even if they werenâ€™t in the lowest satisfaction range. The distribution plot shows a spread across various evaluation levels, indicating no strong concentration in a particular range.\n",
    "\n",
    "## Number of Projects\n",
    "\n",
    "### The average number of projects for employees who left was 4.93, compared to 4.35 for the overall group and 4.31 for those who stayed. This suggests that employees handling more projects were more likely to leave, even at a mid-low satisfaction level. The distribution plot shows that a significant portion of those who left had been handling 4 to 7 projects, suggesting that workload might have been a contributing factor.\n",
    "\n",
    "## Average Monthly Hours\n",
    "\n",
    "### Employees who left had an average of 203.1 monthly hours, which is slightly higher than the groupâ€™s mean of 196.77 and also higher than the 196.31 mean for those who stayed. While this is not as stark as the difference seen in the low satisfaction group, it still suggests that those working more hours were more likely to leave. The distribution plot highlights that those who left were spread across a wide range of working hours, with a notable concentration around 150 and 200-250 hours.\n",
    "\n",
    "## Time Spent at Company\n",
    "\n",
    "### The average tenure for employees who left was 3.88 years, which is slightly lower than the groupâ€™s mean of 4.30 years and also lower than the 4.33 mean for those who stayed. This suggests that employees were leaving after gaining some experience but before establishing long-term tenure. The distribution plot of time spent at the company indicates that many employees who left had spent between 2 to 5 years with the company.\n",
    "\n",
    "## #Departmental Analysis\n",
    "\n",
    "### The percentage of employees who left varied significantly by department, with accounting (18.42%) and support (8.22%) showing higher attrition rates compared to IT (1.35%) and R&D (5.26%). This indicates that specific departments might have faced particular challenges or dissatisfaction leading to higher turnover, even at mid-low satisfaction levels.\n",
    "\n",
    "## Salary\n",
    "\n",
    "### Attrition was highest among those in the low salary range (10.7%), followed by the medium salary range (3.5%), and lowest in the high salary range (1.77%). This suggests that salary had some mitigating effect on turnover, but even low satisfaction paired with low salary led to a higher likelihood of leaving.\n",
    "\n",
    "## Promotions and Work Accidents\n",
    "\n",
    "### None of the employees who left had received a promotion in the last 5 years, indicating that lack of career progression might have contributed to their decision to leave. Additionally, a lower proportion of those who had work accidents left (1.53%) compared to those who did not have accidents (7.95%), though this difference is less pronounced than in other satisfaction ranges.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "### Employees at this mid-low satisfaction level had a relatively low attrition rate overall, but those who left were often handling more projects and working more hours than those who stayed. Although their satisfaction levels were slightly higher, these employees still left, possibly due to a combination of workload, lack of career progression, and potentially feeling undervalued. Departmental differences in attrition rates in accounting suggest that this department may need more targeted interventions to improve employee retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass satisfaction_med dataframe to satisfaction_stats function\n",
    "satisfaction_stats(satisfaction_med)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of satisfaction level for those who left at medium satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med[satisfaction_med['left']==1]['satisfaction_level'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Satisfaction Level for those who left at medium satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of last evaluation for those who left at medium satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med[satisfaction_med['left']==1]['last_evaluation'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Last Evaluation for those who left at medium satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of average monthly hours for those who left at medium satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med[satisfaction_med['left']==1]['average_montly_hours'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Average Monthly Hours for those who left at medium satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of number of projects for those who left at medium satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med[satisfaction_med['left']==1]['number_project'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Number of Projects for those who left at medium satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Distribution of time spent at the company for those who left at medium satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med[satisfaction_med['left']==1]['time_spend_company'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Time Spent at Company for those who left at medium satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Ploytly boxplot of salaries for those who left at medium satisfaction level with title\n",
    "import plotly.express as px\n",
    "fig = px.box(satisfaction_med[satisfaction_med['left']==1], x='salary', y='satisfaction_level', points='all', title='Boxplot of Salaries for those who left at medium satisfaction level')\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Medium Satisfaction Level Employees\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Total number of employees at this satisfaction level: 2,091\n",
    "### Total number of employees who left: 1,556\n",
    "### Percentage of employees who left: 74.41%\n",
    "### Percentage of employees who left at this satisfaction level compared to overall total: 43.57%\n",
    "\n",
    "## Satisfaction Level\n",
    "\n",
    "### The mean satisfaction level of employees who left was 0.408, which is almost the same as the mean for those who stayed at 0.410. This suggests that satisfaction level alone was not a strong determinant for leaving at this range. The distribution plot shows a relatively even spread of employees who left across the satisfaction range from 0.35 to 0.47, indicating that other factors besides satisfaction might have played a significant role.\n",
    "\n",
    "## Last Evaluation\n",
    "\n",
    "### ##The mean last evaluation score for employees who left was 0.516, lower than the company average and significantly lower than the 0.617 mean for those who stayed. This suggests that employees with medium satisfaction levels who had lower evaluations were more likely to leave. The distribution plot shows a sharp decline in employees who left as the last evaluation score increases, implying that better evaluations might have provided some retention incentive.\n",
    "\n",
    "\n",
    "## Number of Projects\n",
    "\n",
    "### The number of projects assigned to employees who left had a mean of 2.05, compared to 3.57 for those who stayed. This indicates that employees with fewer projects, despite having a medium satisfaction level, were more likely to leave. The distribution plot further shows that the majority of those who left had only 2 projects, which could imply either underutilization or dissatisfaction with their workload.\n",
    "\n",
    "## Average Monthly Hours\n",
    "\n",
    "### The average monthly hours for those who left was 145.85, compared to 173.72 for those who stayed. Employees with medium satisfaction levels who left generally worked fewer hours, suggesting that they might not have been fully engaged or motivated. The distribution plot supports this, showing a high concentration of employees who left with fewer hours.\n",
    "\n",
    "## Time Spent at Company\n",
    "\n",
    "### Employees who left had an average tenure of 3.02 years, slightly less than the 3.64 years for those who stayed. This indicates that employees with medium satisfaction levels tended to leave before reaching longer tenure milestones. The distribution plot of time spent at the company shows a peak at 3 years, indicating many left after this period, possibly as they assessed their career progression.\n",
    "\n",
    "## Departmental Analysis\n",
    "\n",
    "### The attrition rates across departments were high, with HR having the highest at 83.21%, followed by marketing at 79.26%, and sales at 76.71%. The lowest attrition was in R&D at 55.70%. This suggests that the reasons for leaving might have been more company-wide rather than department-specific, although some departments were more affected.\n",
    "\n",
    "## Salary\n",
    "\n",
    "### Salary did appear to have some impact, with lower salary ranges experiencing higher attrition (79.72%) compared to medium (70.63%) and high salary ranges (43.52%). The boxplot shows that even among higher salaries, a significant proportion of employees still left, indicating that salary alone was not sufficient to retain them.\n",
    "\n",
    "## Promotions and Work Accidents\n",
    "\n",
    "### Promotions had minimal impact, with only a small percentage of employees in this satisfaction range receiving promotions, and many of those still left. Regarding work accidents, 76.72% of employees who did not have accidents left, compared to 46.20% of those who did, suggesting that accidents may have provided a slight retention effect, perhaps due to company support or benefits during recovery.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "### Employees with medium satisfaction levels left the company in large numbers, driven by factors other than satisfaction, such as lower evaluations, fewer projects, and shorter tenure. Compared to the low satisfaction employees who left, this group seems to have been actually underworked. Salary and departmental differences played a role, but they were not the primary reasons for leaving. The company might need to focus on better engaging these employees by aligning workload, providing growth opportunities, and improving performance evaluation processes to reduce turnover in this group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass satisfaction_med_high dataframe to satisfaction_stats function\n",
    "satisfaction_stats(satisfaction_med_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of satisfaction level for those who left at medium high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_high[satisfaction_med_high['left']==1]['satisfaction_level'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Satisfaction Level for those who left at medium high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of last evaluation for those who left at medium high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_high[satisfaction_med_high['left']==1]['last_evaluation'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Last Evaluation for those who left at medium high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of average monthly hours for those who left at medium high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_high[satisfaction_med_high['left']==1]['average_montly_hours'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Average Monthly Hours for those who left at medium high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of number of projects for those who left at medium high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_high[satisfaction_med_high['left']==1]['number_project'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Number of Projects for those who left at medium high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Distribution of time spent at the company for those who left at medium high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_med_high[satisfaction_med_high['left']==1]['time_spend_company'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Time Spent at Company for those who left at medium high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Ploytly boxplot of salaries for those who left at medium high satisfaction level with title\n",
    "import plotly.express as px\n",
    "fig = px.box(satisfaction_med_high[satisfaction_med_high['left']==1], x='salary', y='satisfaction_level', points='all', title='Boxplot of Salaries for those who left at medium high satisfaction level')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Medium-High Satisfaction Level Employees\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Total number of employees at this satisfaction level: 4,271\n",
    "### Total number of employees who left: 93\n",
    "### Percentage of employees who left: 2.18%\n",
    "### Percentage of employees who left at this satisfaction level compared to the overall total: 2.6%\n",
    "\n",
    "## Satisfaction Level\n",
    "\n",
    "### The mean satisfaction level for employees who left is 0.571, slightly lower than the group's mean satisfaction level of 0.586 and lower than the 0.586 mean for those who stayed. This suggests that while employees at this satisfaction level generally had higher satisfaction, there were still factors leading a small percentage to leave. The distribution plot shows a relatively even spread across the range, with a slight concentration around the middle values.\n",
    "\n",
    "## Last Evaluation\n",
    "\n",
    "### The mean last evaluation score for employees who left was 0.740, higher than the company's overall mean of 0.716 and higher than the 0.715 mean for those who stayed. This indicates that employees with high performance evaluations were more likely to leave, which may suggest feelings of being undervalued or overworked despite high performance. The distribution plot shows clusters at higher evaluation scores, reinforcing this observation.\n",
    "\n",
    "## Number of Projects\n",
    "\n",
    "### The number of projects assigned to employees who left was slightly higher, with a mean of 3.92 compared to 3.69 for those who stayed. This suggests that employees with more projects were more likely to leave. The distribution plot shows a concentration around 3 to 4 projects, which is within the typical range but slightly on the higher side.\n",
    "\n",
    "## Average Monthly Hours\n",
    "\n",
    "### The average monthly hours for those who left was 220, compared to 199 for those who stayed. This difference indicates that overwork could have been a contributing factor to their decision to leave. The distribution plot shows a peak around 240 to 250 hours, suggesting that those who left were working significantly more hours than the company average.\n",
    "\n",
    "## Time Spent at Company\n",
    "\n",
    "### Employees who left had an average tenure of 3.94 years, slightly higher than the 3.28 years for those who stayed. This suggests that employees with a longer tenure may have been more likely to leave, possibly due to a lack of further growth opportunities or increased job dissatisfaction over time. The distribution plot shows peaks around the 4 to 5-year mark, indicating a trend of leaving after reaching a certain tenure.\n",
    "\n",
    "## Departmental Analysis\n",
    "\n",
    "### The departmental analysis shows that the attrition rate varies by department, with the highest attrition rates in HR (3.86%) and Technical (3.88%). This indicates that while overall attrition at this satisfaction level is low, certain departments have slightly higher turnover, which may be related to specific departmental challenges or cultures.\n",
    "\n",
    "## Salary\n",
    "\n",
    "### #Salary analysis shows that employees with low salaries had a higher attrition rate of 2.95%, compared to 1.76% for medium salaries and 0.68% for high salaries. This suggests that lower-paid employees were more likely to leave, even within this higher satisfaction range. The boxplot further supports this, showing a concentration of those who left within the low salary range.\n",
    "\n",
    "## Promotions and Work Accidents\n",
    "\n",
    "### #Promotions and work accidents had minimal influence on turnover at this satisfaction level. Only 2.58% of employees without work accidents left, and just 0.27% of those with work accidents left. Similarly, none of the employees who left had received a promotion in the last 5 years, indicating that a lack of career advancement might have been a factor.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "### Employees with medium-high satisfaction levels generally had lower attrition rates, but those who left tended to work more hours, had slightly higher evaluation scores, and more projects. Departments like HR and Technical had slightly higher turnover, and lower salary ranges also correlated with higher attrition. This analysis suggests that even at higher satisfaction levels, overwork and pay dissatisfaction can still drive some employees to leave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass satisfaction_high dataframe to satisfaction_stats function\n",
    "satisfaction_stats(satisfaction_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of satisfaction level for those who left at high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_high[satisfaction_high['left']==1]['satisfaction_level'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Satisfaction Level for those who left at high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of last evaluation for those who left at high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_high[satisfaction_high['left']==1]['last_evaluation'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Last Evaluation for those who left at high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of average monthly hours for those who left at high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_high[satisfaction_high['left']==1]['average_montly_hours'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Average Monthly Hours for those who left at high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of number of projects for those who left at high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_high[satisfaction_high['left']==1]['number_project'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Number of Projects for those who left at high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Distribution of time spent at the company for those who left at high satisfaction level\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(satisfaction_high[satisfaction_high['left']==1]['time_spend_company'], kde=True, color='red', label='Left',bins=10)\n",
    "plt.title('Distribution of Time Spent at Company for those who left at high satisfaction level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Ploytly boxplot of salaries for those who left at high satisfaction level with title\n",
    "import plotly.express as px\n",
    "fig = px.box(satisfaction_high[satisfaction_high['left']==1], x='salary', y='satisfaction_level', points='all', title='Boxplot of Salaries for those who left at high satisfaction level')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of High Satisfaction Level Employees\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Total number of employees at this satisfaction level: 6,503\n",
    "### Total number of employees who left: 943\n",
    "### Percentage of employees who left: 14.5%\n",
    "### Percentage of employees who left at this satisfaction level compared to the overall total: 26.41%\n",
    "\n",
    "## Satisfaction Level\n",
    "\n",
    "### The mean satisfaction level for employees who left is 0.818, which is slightly lower than the mean satisfaction level of 0.841 for the group and 0.845 for those who stayed. This indicates that although these employees were generally satisfied, there were still factors prompting them to leave. The distribution plot shows that the satisfaction levels of those who left are spread across the high range, with peaks around the 0.8 mark.\n",
    "\n",
    "## Last Evaluation\n",
    "\n",
    "### The mean last evaluation score for employees who left was 0.910, which is significantly higher than the overall group mean of 0.755 and much higher than the 0.729 mean for those who stayed. This suggests that high-performing employees were more likely to leave, possibly due to being overworked or feeling underappreciated despite their high performance. The distribution plot shows a strong cluster at the highest evaluation scores, reinforcing this observation.\n",
    "\n",
    "## Number of Projects\n",
    "\n",
    "### Employees who left had an average of 4.53 projects, which is higher than the 3.88 projects for the entire group and 3.77 projects for those who stayed. This suggests that employees with a higher number of projects were more likely to leave, potentially due to the pressure or workload associated with handling multiple projects. The distribution plot highlights a concentration around 4 to 5 projects.\n",
    "\n",
    "## Average Monthly Hours\n",
    "\n",
    "### The average monthly hours for those who left was 242.86, compared to 207.58 for the entire group and 201.59 for those who stayed. This significant difference indicates that overwork could have been a major factor in their decision to leave. The distribution plot shows a clear peak around 240 to 250 hours, suggesting that those who left were working more hours than their peers.\n",
    "\n",
    "## Time Spent at Company\n",
    "\n",
    "### Employees who left had an average tenure of 5.08 years, which is higher than the 3.49 years for the entire group and 3.22 years for those who stayed. This suggests that longer-tenured employees were more likely to leave, possibly due to a lack of further career growth opportunities or increasing job dissatisfaction over time. The distribution plot shows a peak around the 5-year mark, indicating a trend of leaving after reaching a certain tenure.\n",
    "\n",
    "## Departmental Analysis\n",
    "\n",
    "### The departmental analysis shows that the attrition rate varies by department, with the highest attrition rates in Product Management (16.58%), HR (16.05%), and Technical (16.03%). This indicates that while the overall attrition rate is moderate at this satisfaction level, certain departments experience higher turnover, potentially due to specific departmental challenges or cultures.\n",
    "\n",
    "## Salary\n",
    "\n",
    "### Salary analysis reveals that employees with low salaries had a higher attrition rate of 18.48%, compared to 12.43% for medium salaries and only 2.75% for high salaries. This suggests that lower-paid employees were more likely to leave, even within this higher satisfaction range. The boxplot supports this, showing a concentration of those who left within the low salary range.\n",
    "\n",
    "## Promotions and Work Accidents\n",
    "\n",
    "### Promotions and work accidents had some influence on turnover at this satisfaction level. About 16.32% of employees without work accidents left, while only 4.58% of those with work accidents left. The promotion rate among those who left was also minimal, with only 0.42% of employees who left having received a promotion in the last 5 years, indicating that a lack of career advancement might have been a factor.\n",
    "\n",
    "## Conclusion\n",
    "### Employees with high satisfaction levels accounted for about 26% of all the employees who left the compnay. Those who left were characterized by higher last evaluation scores, more projects, longer tenures, and higher average monthly hours, suggesting that overwork and possibly lack of recognition played significant roles in their decision to leave. Departments such as Product Management, HR, and Technical had the highest turnover, and lower salary ranges correlated with higher attrition. This analysis suggests that even at high satisfaction levels, issues like workload, recognition, and compensation can still drive employees to leave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Recommendations for Machine Learning Features\n",
    "\n",
    "## Conclusion\n",
    "### The analysis across different satisfaction levels reveals several key insights into the factors driving employee attrition:\n",
    "\n",
    "## Low Satisfaction Level Employees:\n",
    "### Employees with low satisfaction levels had the highest attrition rates, with many leaving despite low evaluation scores and relatively low project workloads.\n",
    "### Overwork, lack of promotion, and dissatisfaction with salary, especially among low earners, were significant contributors to turnover.\n",
    "\n",
    "## Medium-Low Satisfaction Level Employees:\n",
    "### Employees in this category also exhibited high attrition rates, with notable correlations between higher evaluation scores, longer tenure, and increased likelihood of leaving.\n",
    "### High-performing employees, particularly those with more projects and longer working hours, were more likely to leave, suggesting dissatisfaction despite their contributions.\n",
    "\n",
    "## Medium Satisfaction Level Employees:\n",
    "### Attrition in this group was driven by a combination of higher workload (more projects and longer hours) and tenure. Employees who had spent more time at the company were more prone to leave, likely due to stagnation or lack of growth opportunities.\n",
    "### Departments like HR and Technical showed slightly higher turnover, indicating possible cultural or operational issues within these areas.\n",
    "\n",
    "## Medium-High Satisfaction Level Employees:\n",
    "### While the overall attrition rate was lower in this group, those who left tended to have high evaluation scores, more projects, and longer working hours, pointing to overwork and underappreciation as potential causes.\n",
    "### Employees with lower salaries within this satisfaction range were also more likely to leave, highlighting the impact of compensation on retention.\n",
    "\n",
    "## High Satisfaction Level Employees:\n",
    "### Even among employees with high satisfaction, there was still notable attrition, particularly among those with very high performance evaluations, multiple projects, and long tenures.\n",
    "### The impact of salary was also evident, with lower-paid employees being more likely to leave, even if they were generally satisfied with their jobs.\n",
    "\n",
    "## Recommended Features for Machine Learning Model\n",
    "### To forecast employees at risk of leaving the company, the following features should be considered for inclusion in a predictive Machine Learning model:\n",
    "\n",
    "### Satisfaction Level: As a primary indicator, employees with lower satisfaction levels are more likely to leave.\n",
    "### Last Evaluation Score: High evaluation scores, particularly among those who are still leaving, suggest dissatisfaction despite high performance.\n",
    "### Number of Projects: Employees with more projects are at a higher risk of attrition, potentially due to workload pressure.\n",
    "### Average Monthly Hours: Overworking is a significant factor in attrition; employees working significantly more hours than average are more likely to leave.\n",
    "### Time Spent at Company (Tenure): Employees with longer tenures, particularly around 3-5 years, tend to be at higher risk of leaving.\n",
    "### Department: Certain departments, such as HR, Technical, and Product Management, have higher attrition rates, making department an important feature.\n",
    "### Salary: Lower salary ranges correlate with higher attrition, even within higher satisfaction levels, making this a crucial feature.\n",
    "### Work Accident History: Employees who have experienced work accidents may have different risk levels for attrition.\n",
    "### Promotion Status: Lack of promotions in the last 5 years is linked to higher attrition, especially among high-performing employees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next we'll perform clustering using k-means and elbow method to find optimal number of clusters of employees who left based on their satisfaction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Filter the data for employees who left\n",
    "df_left = df[df['left'] == 1].copy()\n",
    "\n",
    "# Select the relevant features: satisfaction_level and last_evaluation\n",
    "X = df_left[['satisfaction_level', 'last_evaluation']]\n",
    "\n",
    "# Use the elbow method to find the optimal number of clusters\n",
    "wcss = []  # within-cluster sum of squares\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow method graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), wcss, marker='o')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "# Perform K-means clustering with the chosen number of clusters (e.g., 3)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_left.loc[:, 'cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_left, x='satisfaction_level', y='last_evaluation', hue='cluster', palette='viridis', s=100)\n",
    "plt.title('Clusters of Employees Who Left Based on Satisfaction and Evaluation')\n",
    "plt.xlabel('Satisfaction Level')\n",
    "plt.ylabel('Last Evaluation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Summary thus far:\n",
    "\n",
    "## The analysis of employee turnover across different satisfaction level ranges reveals a complex interplay between satisfaction, workload, and performance evaluations. Employees with low satisfaction levels (<0.15) exhibited the highest turnover rates, with over 86% leaving the company, often correlating with high last evaluations and heavy workloads. This suggests that even high-performing employees may leave if they feel overworked and undervalued. In contrast, employees in the medium-low and medium satisfaction ranges (0.15 - 0.47) displayed significantly lower turnover rates, particularly when their workload was more manageable, although the medium range still had notable turnover due to lower last evaluations and fewer projects.\n",
    "\n",
    "## The medium-high satisfaction group (0.48 - 0.69) showed the lowest attrition rates, reinforcing the idea that higher satisfaction, coupled with balanced workloads, contributes to retention. However, in the high satisfaction range (0.7 - 1.0), turnover increased again, though it was still lower compared to the low satisfaction group. Interestingly, these employees often had higher last evaluations and were involved in more projects, indicating that even satisfied employees may leave if they are highly engaged and possibly seeking greater challenges or career advancement elsewhere.\n",
    "\n",
    "## The K-means clustering analysis, validated by the Elbow Method, aligns with these findings by identifying distinct clusters based on satisfaction and last evaluation metrics. The clustering confirms that employees who left can be grouped into meaningful categories, with clear patterns emerging between low satisfaction/high evaluation and turnover, and medium to high satisfaction/low evaluation and retention. This clustering provides additional insight into the role of performance evaluations in turnover decisions, suggesting that while satisfaction is a critical factor, the perceived fairness of workload and evaluations also plays a significant role in employee retention. Overall, the combined analysis underscores the need for balanced workload distribution and recognition of employee performance to reduce turnover, particularly among those with high evaluations and low satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we will create a scatter plot of the original data for employees who left and employees who stayed based on satisfaction level vs last evaluation and use SMOTE to deal with imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install imbalanced-learn library to impot SMOTE\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Visualize the original data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['satisfaction_level'], df['last_evaluation'], c=df['left'], cmap='coolwarm', alpha=0.6)\n",
    "plt.title('Scatter Plot of Satisfaction vs. Last Evaluation (Original Data)')\n",
    "plt.xlabel('Satisfaction Level')\n",
    "plt.ylabel('Last Evaluation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to handle class imbalance\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[['satisfaction_level', 'last_evaluation']]\n",
    "y = df['left']\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Step 3: Visualize the data after applying SMOTE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_resampled['satisfaction_level'], X_resampled['last_evaluation'], c=y_resampled, cmap='coolwarm', alpha=0.6)\n",
    "plt.title('Scatter Plot of Satisfaction vs. Last Evaluation (After SMOTE)')\n",
    "plt.xlabel('Satisfaction Level')\n",
    "plt.ylabel('Last Evaluation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform k-fold cross-validation model training and evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In order to use a machie learning model we'll first do one-hot encoding for the department column \n",
    "# And then convert the salary column to numerical categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll implement one-hot encoding for 'department' column\n",
    "df = pd.get_dummies(df, columns=['department'], drop_first=True,dtype='int64')\n",
    "print(df.head())\n",
    "print()\n",
    "df.info()\n",
    "# Convert the 'salary' column to numerical values using dummy variables\n",
    "df = pd.get_dummies(df, columns=['salary'], drop_first=True,dtype='int64')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We'll start our testing of ML models with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('left', axis=1)  # Drop the target variable from features\n",
    "y = df['left']  # Target variable\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000)  # Increase the number of iterations\n",
    "\n",
    "\n",
    "# Define the K-fold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "accuracy = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "precision = cross_val_score(model, X, y, cv=kf, scoring='precision')\n",
    "recall = cross_val_score(model, X, y, cv=kf, scoring='recall')\n",
    "f1 = cross_val_score(model, X, y, cv=kf, scoring='f1')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f'Average Accuracy: {accuracy.mean():.4f}')\n",
    "print(f'Average Precision: {precision.mean():.4f}')\n",
    "print(f'Average Recall: {recall.mean():.4f}')\n",
    "print(f'Average F1-Score: {f1.mean():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We next do feature scaling using StandardScaler to scale the features to have zero mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline that first scales the data then applies logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('log_reg', LogisticRegression(max_iter=1000))  # Increase max_iter if necessary\n",
    "])\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "accuracy = cross_val_score(pipeline, X, y, cv=kf, scoring='accuracy')\n",
    "precision = cross_val_score(pipeline, X, y, cv=kf, scoring='precision')\n",
    "recall = cross_val_score(pipeline, X, y, cv=kf, scoring='recall')\n",
    "f1 = cross_val_score(pipeline, X, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f'Average Accuracy: {accuracy.mean():.4f}')\n",
    "print(f'Average Precision: {precision.mean():.4f}')\n",
    "print(f'Average Recall: {recall.mean():.4f}')\n",
    "print(f'Average F1-Score: {f1.mean():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis thus far:\n",
    "\n",
    "## Our model gives us an accuracy of 79% which although not horrible, it is not great, as we would like to get accuracy as close into the 90th percentile as possible\n",
    "## Likewise our precision of 60.9% means that only about 60.9% of the employees that we identify as leaving actually do. This could be improved\n",
    "## The recall of 35.32% tell us that overall we are only identifying about 35 % of the employees who will leave, which is way too low and suggests that we might be missing potential features that could help us predict more accurately those who are at risk of leaving\n",
    "## The F-1 score is rather low\n",
    "## Overall, we need to work on our features or the model itself in order to get all our averages for precision, recall and f1 into the 80th percentile and the accuracy into the 99h percentile\n",
    "\n",
    "## Given our earlier analysis, we need to increase the number of features to include. As we saw in our initial EDA, monthly hours an number of projects played a role for those who left the company so we'll add the monthly hours and number of projects to the features for our regression model and see if performance improves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your original DataFrame after processing\n",
    "X = df[['satisfaction_level', 'last_evaluation', 'average_montly_hours', 'number_project']]  # features to test\n",
    "y = df['left']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring methods\n",
    "scoring_methods = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# Perform cross-validation for each scoring method\n",
    "scores = {method: cross_val_score(model, X, y, cv=kf, scoring=scoring_method).mean() for method, scoring_method in scoring_methods.items()}\n",
    "\n",
    "# Output the results\n",
    "for method, score in scores.items():\n",
    "    print(f\"Average {method.capitalize()}: {score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since we don't see any improvement and actually see worse performance accross the board, we'll try different models and compare their different precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define  feature matrix X and target variable y\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define feature matrix X and target variable y\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define feature matrix X and target variable y\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Support Vector Classifier with an RBF kernel\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='auto', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define feature matrix X and target variable y\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting Classifier\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Keras library\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Define feature matrix X and target variable y\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Build and compile the neural network model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Performance on Test Data:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation with Neural Network\n",
    "def create_model():\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Input(shape=(X_train.shape[1],)))\n",
    "    nn_model.add(Dense(units=16, activation='relu'))\n",
    "    nn_model.add(Dense(units=8, activation='relu'))\n",
    "    nn_model.add(Dense(units=1, activation='sigmoid'))\n",
    "    nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return nn_model\n",
    "\n",
    "cv_model = KerasClassifier(model=create_model, epochs=50, batch_size=10, verbose=0)\n",
    "\n",
    "# Define KFold Cross Validator\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# Perform Cross-Validation\n",
    "results = cross_validate(cv_model, X_scaled, y, cv=kf, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "# Output the results of cross-validation\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {results['test_accuracy'].mean():.4f}\")\n",
    "print(f\"Average Precision: {results['test_precision'].mean():.4f}\")\n",
    "print(f\"Average Recall: {results['test_recall'].mean():.4f}\")\n",
    "print(f\"Average F1-Score: {results['test_f1'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Models:\n",
    "\n",
    "## Looking at the ML models above, we can see that the Random Forest Classifier gives us the best performance\n",
    "\n",
    "## Per our previous initial analysis we see that being overworked, or underworked as defined by the number of hours per month worked and the number of project assigned have an influence in the satisfaction level. As we can see in the ML models, including monthly hours, project number, satisfaction level and last evaluation give us good performance in the 90th percentiles across the board for the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Would including salary levels give us even better performance? We will test this next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define  feature matrix X and target variable y\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'salary_low', 'salary_medium']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original RandomForesClassifier only with satisfaction_level, last eval, project number and average monthly hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define  feature matrix X and target variable y\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding promotion in last 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define  feature matrix X and target variable y\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'salary_low', 'salary_medium','promotion_last_5years']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding work_accident to the features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define  feature matrix X and target variable yarketing\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'salary_low', 'salary_medium', 'promotion_last_5years', 'Work_accident']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Time spend at compnay to the features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define  feature matrix X and target variable yarketing\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'salary_low', 'salary_medium', 'promotion_last_5years', 'Work_accident', 'time_spend_company']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best performance is given thus far by these features in the RandomForestClassifier:\n",
    "# Satisfaction Level\n",
    "# Last Evaluation\n",
    "# Number of Projects\n",
    "# Avergage Monthly Hours\n",
    "# Salary category\n",
    "# Promotion in last 5 years\n",
    "# Work accident\n",
    "# Time spent at company\n",
    "\n",
    "# Would we get something similar if we take out Promotion and Work Accident which did not seem to add to the performance prior to time spent at company was added?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define  feature matrix X and target variable yarketing\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'salary_low', 'salary_medium', 'time_spend_company']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apparently all features are needed, for best performance, as taking out promotion and work accidents from the features lowers the scores a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, let's add department categories to see if that adds to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding departnments to the features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define  feature matrix X and target variable yarketing\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'salary_low', 'salary_medium', 'promotion_last_5years', 'Work_accident', 'time_spend_company', 'department_RandD', 'department_accounting', 'department_hr', 'department_management', 'department_marketing', 'department_product_mng', 'department_sales', 'department_support', 'department_technical']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding departments does not improve performance, so our final recommendations are the following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Recommendations\n",
    "\n",
    "## As we gathered from our original EDA prior to testing ML models, various features seemed to affect the employee decisions to leave across different satisfaction ranges\n",
    "\n",
    "## Best Model to use: RandomForestClassifier\n",
    "\n",
    "## Best Predictive Features for our dataset:\n",
    "\n",
    "## Satisfaction Level\n",
    "## Last Evaluation\n",
    "## Number of Projects\n",
    "## Avergage Monthly Hours\n",
    "## Salary category\n",
    "## Promotion in last 5 years\n",
    "## Work accident\n",
    "## Time spent at company\n",
    "\n",
    "## These fetures will give us the best performance metrics as seen below:\n",
    "\n",
    "### Accuracy: 0.9878\n",
    "### Precision: 0.9913\n",
    "### Recall: 0.9571\n",
    "### F1-Score: 0.9739\n",
    "### Cross-Validated Accuracy: 0.9921\n",
    "### Cross-Validated Precision: 0.9946\n",
    "### Cross-Validated Recall: 0.9722\n",
    "### Cross-Validated F1-Score: 0.9832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier with best predictive features to predict employee attrition\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define  feature matrix X and target variable yarketing\n",
    "features = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'salary_low', 'salary_medium', 'promotion_last_5years', 'Work_accident', 'time_spend_company']\n",
    "X = df[features]\n",
    "y = df['left']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Cross-Validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "cv_precision = cross_val_score(model, X_scaled, y, cv=kf, scoring='precision')\n",
    "cv_recall = cross_val_score(model, X_scaled, y, cv=kf, scoring='recall')\n",
    "cv_f1 = cross_val_score(model, X_scaled, y, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validated Accuracy: {cv_accuracy.mean():.4f}\")\n",
    "print(f\"Cross-Validated Precision: {cv_precision.mean():.4f}\")\n",
    "print(f\"Cross-Validated Recall: {cv_recall.mean():.4f}\")\n",
    "print(f\"Cross-Validated F1-Score: {cv_f1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retention Strategies to retain employees at risk of leaving the Company:\n",
    "\n",
    "## To retain employees and reduce turnover, our analysis suggests that the company should focus on managing workloads, ensuring fair compensation, and addressing employee satisfaction. Employees with low satisfaction levels were often overworked, handling more projects and working longer hours, which, despite leading to high evaluation scores, likely contributed to their decision to leave due to burnout and dissatisfaction. Conversely, those in the mid-satisfaction range seemed underutilized, with fewer projects and hours, indicating a potential for disengagement. Across all satisfaction ranges, employees who were tasked with more projects and hours, yet received lower compensation compared to their peers, were more likely to leave. Therefore, it is crucial to balance workloads, ensure equitable pay across similar roles, and regularly assess and address employee satisfaction to retain talent. Additionally, offering growth opportunities and recognizing the contributions of employees through promotions and incentives could further reduce turnover and foster a more committed workforce. By focusing on these areas, the company can create a more supportive and motivating environment, leading to higher employee retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
